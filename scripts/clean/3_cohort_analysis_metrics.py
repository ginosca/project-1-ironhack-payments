# ğŸ“ˆ Cohort Metrics Script â€“ Ironhack Payments
# ğŸ““ Source Notebook: 3_cohort_analysis_metrics.ipynb
# ğŸ“Š Description: Calculates monthly cohort KPIs: user retention, frequency, incidents, and revenue.
# ğŸ“… Date: December 13, 2024
# ğŸ‘©â€ğŸ’» Author: Ginosca Alejandro DÃ¡vila
# ğŸ› ï¸ Bootcamp: Ironhack Data Science and Machine Learning

#!/usr/bin/env python
# coding: utf-8

# In[1]:


import sys
import os

# âœ… Safe print to avoid encoding issues
def safe_print(text):
    try:
        print(text)
    except UnicodeEncodeError:
        print(text.encode("ascii", errors="ignore").decode())

# âœ… Check for Colab environment
def is_colab():
    return 'google.colab' in sys.modules

# âœ… Set base path dynamically
if is_colab():
    from google.colab import drive
    drive.mount('/content/drive')

    # Try default user path (adjustable)
    default_path = 'MyDrive/Colab Notebooks/Ironhack/Week 2/Week 2 - Day 4/project-1-ironhack-payments-2-en'
    full_default_path = os.path.join('/content/drive', default_path)

    if os.path.exists(full_default_path):
        project_base_path = full_default_path
        safe_print(f"âœ… Colab project path set to: {project_base_path}")
    else:
        safe_print("\nğŸ“‚ Default path not found. Please input the relative path to your project inside Google Drive.")
        safe_print("ğŸ‘‰ Example: 'MyDrive/Colab Notebooks/Ironhack/Week 2/Week 2 - Day 4/project-1-ironhack-payments-2-en'")
        user_path = input("ğŸ“¥ Your path: ").strip()
        project_base_path = os.path.join('/content/drive', user_path)

        if not os.path.exists(project_base_path):
            raise FileNotFoundError(f"âŒ Path does not exist: {project_base_path}\nPlease check your input.")

        safe_print(f"âœ… Colab project path set to: {project_base_path}")
else:
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
    except NameError:
        script_dir = os.getcwd()

    # Assume script is inside /scripts/ and go two levels up
    project_base_path = os.path.abspath(os.path.join(script_dir, '..', '..'))
    safe_print(f"âœ… Local environment detected. Base path set to: {project_base_path}")


# In[2]:


import pandas as pd
import os

# ğŸ“‚ Define EDA output directory path
eda_data_path = os.path.join(project_base_path, 'eda_outputs', 'data')

# ğŸ—‚ï¸ Define file paths
eda_files = {
    'user_first_request': 'user_first_request.csv',
    'monthly_active_users': 'monthly_active_users.csv',
    'transfer_type_share': 'transfer_type_share.csv',
    'merged_cash_fee': 'merged_cash_fee.csv',
}

# ğŸ“¥ Load each file into a DataFrame with error handling
dataframes = {}
safe_print("ğŸ“„ Loading EDA output files...\n")

for key, filename in eda_files.items():
    file_path = os.path.join(eda_data_path, filename)
    safe_print(f"ğŸ“ Looking for: {file_path}")

    try:
        df = pd.read_csv(file_path)
        dataframes[key] = df
        safe_print(f"âœ… Loaded {filename} â†’ Shape: {df.shape}")
    except FileNotFoundError:
        safe_print(f"âŒ File not found: {file_path}")
        safe_print("ğŸ“Œ Check that the file exists and the name is spelled correctly.")
        raise

# ğŸ”„ Unpack dataframes for easy access
user_first_request_df = dataframes['user_first_request']
monthly_active_users_df = dataframes['monthly_active_users']
transfer_type_share_df = dataframes['transfer_type_share']
merged_df = dataframes['merged_cash_fee']


# In[3]:


import io

# âœ… Define display fallback for script environments
try:
    display
except NameError:
    def display(x):
        print(x.to_string() if isinstance(x, pd.DataFrame) else x)

# ğŸ” Inspect basic structure of a DataFrame with optional previews and toggles
def inspect_basic_structure(df, name="Dataset", preview_rows=5, full=False):
    """
    Display structure, sample rows, schema, and optional full view of a DataFrame.
    Compatible with notebooks and terminal scripts.

    Parameters:
    - df: pandas DataFrame
    - name: Custom name to identify the DataFrame
    - preview_rows: Number of rows to show from head and tail
    - full: If True, display the entire DataFrame
    """
    safe_print(f"ğŸ§¾ Inspecting: {name}")
    safe_print("=" * 60)

    # ğŸ‘ï¸ Preview first N rows
    safe_print(f"ğŸ”¹ First {preview_rows} Rows:")
    display(df.head(preview_rows))

    # ğŸ‘ï¸ Preview last N rows
    safe_print(f"\nğŸ”¹ Last {preview_rows} Rows:")
    display(df.tail(preview_rows))

    # ğŸ“ Dataset shape
    safe_print(f"\nğŸ”¹ Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns")

    # ğŸ·ï¸ Column names
    safe_print("\nğŸ”¹ Column Names:")
    safe_print(df.columns.tolist())

    # ğŸ§¬ Data types and non-null counts
    safe_print("\nğŸ”¹ Data Types and Non-Null Counts:")
    buffer = io.StringIO()
    df.info(buf=buffer)
    safe_print(buffer.getvalue())

    # ğŸ§¼ Missing values
    safe_print("\nğŸ”¹ Missing Values (Null Counts):")
    display(df.isnull().sum())

    # ğŸ‘ï¸ Optional: Full DataFrame display
    if full:
        safe_print("\nğŸ”¹ Full Data Preview:")
        display(df)

    safe_print("=" * 60 + "\n")


# In[4]:


# ğŸ” Inspect the user-to-cohort mapping dataset
inspect_basic_structure(user_first_request_df, name="user_first_request.csv")


# In[5]:


# ğŸ” Inspect the Monthly Active Users dataset
inspect_basic_structure(monthly_active_users_df, name="monthly_active_users.csv")


# In[6]:


# ğŸ” Inspect the monthly transfer type distribution dataset
inspect_basic_structure(transfer_type_share_df, name="transfer_type_share.csv")


# In[7]:


# ğŸ” Inspect the merged dataset containing cash requests and associated fees
inspect_basic_structure(merged_df, name="merged_cash_fee.csv")


# In[8]:


# ğŸ“ Merge cohort data into merged_df using final_user_id
safe_print("ğŸ”„ Merging cohort_month into merged_df based on final_user_id...\n")

try:
    # âœ… Merge on final_user_id to assign each request its cohort
    merged_cash_fee_cohort = pd.merge(
        merged_df,
        user_first_request_df[['final_user_id', 'cohort_month', 'cohort_year_month']],
        on='final_user_id',
        how='left'
    )

    # âœ… Confirm the merge was successful
    safe_print("âœ… Merge completed. Cohort assigned to each cash request.")
    safe_print(f"ğŸ“ Updated merged_cash_fee_cohort shape: {merged_cash_fee_cohort.shape}")

except Exception as e:
    safe_print("âŒ Merge failed. Please check the input datasets.")
    raise e


# In[9]:


# âœ… Cohort Assignment Validation
safe_print("\nâœ… Validating cohort assignment...\n")

# ğŸ“ Total number of rows
total_rows = merged_cash_fee_cohort.shape[0]
safe_print(f"ğŸ“ Total rows in merged dataset: {total_rows}")

# â“ Check for missing cohort_month values
missing_cohort_rows = merged_cash_fee_cohort['cohort_month'].isna().sum()
safe_print(f"â“ Rows with missing cohort_month: {missing_cohort_rows}")

# ğŸ‘€ If missing values exist, show preview
if missing_cohort_rows > 0:
    safe_print("\nâš ï¸ Preview of rows with missing cohort_month:")
    display(merged_cash_fee_cohort[merged_cash_fee_cohort['cohort_month'].isna()].head())
else:
    safe_print("âœ… All records have been successfully assigned to a cohort.")

# ğŸ” Check if any users are linked to multiple cohort_months
safe_print("\nğŸ” Verifying cohort consistency across user transactions...")
user_cohort_counts = merged_cash_fee_cohort.groupby('final_user_id')['cohort_month'].nunique()
inconsistent_users = user_cohort_counts[user_cohort_counts > 1]

if inconsistent_users.empty:
    safe_print("âœ… Cohort assignment is consistent: Each user maps to a single cohort_month.")
else:
    safe_print(f"âŒ Found {len(inconsistent_users)} users with multiple cohort_month values!")
    safe_print("ğŸ§ª Sample of affected users and cohort counts:")
    display(inconsistent_users.head())


# In[10]:


# ğŸ‘ï¸ Compact summary preview of merged dataset
safe_print("ğŸ‘ï¸ Previewing merged_cash_fee_cohort (compact summary)...")

# Show selective key columns only
safe_print("\nğŸ“„ First 3 rows (partial columns):")
display(merged_cash_fee_cohort.head(3)[['cash_request_id', 'final_user_id', 'amount', 'cash_status', 'cohort_month']])

safe_print("\nğŸ“„ Last 3 rows (partial columns):")
display(merged_cash_fee_cohort.tail(3)[['cash_request_id', 'final_user_id', 'amount', 'cash_status', 'cohort_month']])

# Print column names
safe_print("\nğŸ“‹ Column names in merged_cash_fee_cohort:")
safe_print(merged_cash_fee_cohort.columns.tolist())

# Show shape
safe_print(f"\nğŸ“ Shape: {merged_cash_fee_cohort.shape[0]} rows Ã— {merged_cash_fee_cohort.shape[1]} columns\n")


# In[11]:


# âœ… Define the custom column order for cohort analysis
new_column_order = [
    # ğŸ§© Cohort metadata
    'final_user_id', 'cohort_month', 'cohort_year_month',

    # ğŸ’³ Cash request details
    'cash_request_id', 'amount', 'cash_status', 'transfer_type',
    'reimbursement_date', 'cash_created_at', 'cash_updated_at',
    'user_id', 'moderated_at', 'deleted_account_id',
    'cash_request_received_date', 'money_back_date', 'send_at',
    'recovery_status', 'reco_creation', 'reco_last_update',
    'year_month', 'month_label', 'recovery_status_clean', 'incident_flag',

    # ğŸ’¸ Fee-related columns
    'fee_id', 'total_amount', 'type', 'fee_status', 'fee_created_at',
    'category', 'reason', 'fee_updated_at', 'paid_at',
    'from_date', 'to_date', 'charge_moment'
]


# ğŸ› ï¸ Apply the reordering if all columns exist
missing_columns = [col for col in new_column_order if col not in merged_cash_fee_cohort.columns]

if not missing_columns:
    merged_cash_fee_cohort = merged_cash_fee_cohort[new_column_order]
    safe_print("âœ… Columns reordered successfully.\n")

    # ğŸ‘ï¸ Preview updated layout (compact, 3 rows)
    safe_print("ğŸ‘ï¸ Preview after reordering (first 3 rows):")
    try:
        display(merged_cash_fee_cohort.head(3))
    except NameError:
        safe_print("(ğŸ” Preview skipped â€“ display not available in .py execution mode)")

    # ğŸ’¾ Save the reordered dataset
    save_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'merged_cash_fee_cohort.csv')
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    try:
        merged_cash_fee_cohort.to_csv(save_path, index=False)
        safe_print(f"ğŸ’¾ Reordered dataset saved to: {save_path}")
    except Exception as e:
        safe_print("âŒ Failed to save the reordered dataset.")
        raise e

else:
    safe_print("âš ï¸ Some expected columns are missing. Could not reorder.")
    safe_print(f"Missing columns: {missing_columns}")


# In[12]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ğŸ“Œ First plot of the notebook
PLOT_INDEX = 1
OVERWRITE_PLOTS = True  # Set to False if you don't want to overwrite existing plots

# ğŸ“Š Frequency of service usage per cohort
safe_print("ğŸ“Š Calculating frequency of service usage per cohort...\n")

try:
    # âœ… Group by cohort and usage month
    cohort_usage = (
        merged_cash_fee_cohort
        .groupby(['cohort_year_month', 'year_month'])
        .size()
        .reset_index(name='num_requests')
    )

    # ğŸ”„ Pivot to form cohort usage matrix
    cohort_usage_matrix = cohort_usage.pivot(
        index='cohort_year_month',
        columns='year_month',
        values='num_requests'
    ).fillna(0).astype(int)

    # âœ… Display full matrix
    safe_print("ğŸ“‹ Cohort usage matrix (cash request counts):")
    with pd.option_context('display.max_rows', None, 'display.max_columns', None):
        display(cohort_usage_matrix)

    # ğŸ’¾ Save cohort matrix to output folder
    output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_usage_matrix.csv')
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    cohort_usage_matrix.to_csv(output_path)
    safe_print(f"\nğŸ’¾ Cohort usage matrix saved to: {output_path}")

    # ğŸ¨ Plot the cohort usage heatmap
    plt.figure(figsize=(14, 8))
    sns.heatmap(
        cohort_usage_matrix,
        annot=True,
        fmt="d",
        cmap="Blues",
        linewidths=0.5,
        linecolor='gray',
        cbar_kws={"label": "Number of Requests"}
    )

    plt.title("Cash Request Frequency per User Cohort", fontsize=16, pad=20)
    plt.xlabel("Activity Month (year_month)")
    plt.ylabel("Cohort (cohort_year_month)")
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.grid(False)

    # âœ… Adjust layout before adding footnote
    plt.tight_layout()

    # âœ… Add the footnote (after tight_layout)
    plt.figtext(
        0.5, -0.05,
        "Note: Nov 2019 and Nov 2020 are partial months â€“ values may be underrepresented.",
        wrap=True,
        horizontalalignment='center',
        fontsize=10,
        color='gray'
    )

    # ğŸ’¾ Save plot with indexed filename (ensure note is saved using bbox_inches='tight')
    plot_filename = f"{PLOT_INDEX:02d}_cohort_usage_heatmap.png"
    plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
    os.makedirs(os.path.dirname(plot_path), exist_ok=True)

    if OVERWRITE_PLOTS or not os.path.exists(plot_path):
        plt.savefig(plot_path, bbox_inches='tight')  # âœ… Save with footnote
        safe_print(f"âœ… Cohort usage heatmap saved to: {plot_path}")
    else:
        safe_print(f"âš ï¸ Skipped saving (already exists): {plot_path}")

    plt.show()

    # ğŸ” Increment plot index
    PLOT_INDEX += 1

except Exception as e:
    safe_print("âŒ Failed to calculate or plot cohort usage matrix.")
    raise e


# In[13]:


# ğŸ“Š Calculate retention rate matrix with dtype compatibility fix
safe_print("\nğŸ“Š Calculating monthly retention rates per cohort...\n")

try:
    # âœ… Load the cohort usage matrix if not already available
    if 'cohort_usage_matrix' not in globals():
        cohort_matrix_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_usage_matrix.csv')
        cohort_usage_matrix = pd.read_csv(cohort_matrix_path, index_col=0)

    # âœ… Create a new DataFrame for retention as float type
    retention_matrix = cohort_usage_matrix.astype(float)

    # âœ… Normalize each row by its first non-zero value (first month of cohort)
    for idx, row in retention_matrix.iterrows():
        first_value = row[row > 0].iloc[0] if any(row > 0) else None
        if first_value and first_value != 0:
            retention_matrix.loc[idx] = (row / first_value).round(3)
        else:
            retention_matrix.loc[idx] = 0.0

    # âœ… Display the matrix
    safe_print("ğŸ“‹ Retention rate matrix (proportions):")
    display(retention_matrix)

    # ğŸ’¾ Save to file
    retention_output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_retention_matrix.csv')
    os.makedirs(os.path.dirname(retention_output_path), exist_ok=True)
    retention_matrix.to_csv(retention_output_path)
    safe_print(f"\nğŸ’¾ Retention matrix saved to: {retention_output_path}")

except Exception as e:
    safe_print("âŒ Failed to compute retention matrix.")
    raise e


# In[14]:


import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd

# ğŸ”§ Plot-saving config
OVERWRITE_PLOTS = True  # Set False to skip re-saving existing images

# ğŸ”„ Load the retention matrix
retention_matrix_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_retention_matrix.csv')
retention_matrix = pd.read_csv(retention_matrix_path, index_col=0)

# ğŸ¨ Plot the heatmap
plt.figure(figsize=(14, 8))
sns.heatmap(
    retention_matrix,
    annot=True,
    fmt=".2f",
    cmap="YlGnBu",
    linewidths=0.5,
    linecolor='gray',
    cbar_kws={"label": "Retention Rate"}
)

plt.title("Monthly Retention Rate per User Cohort", fontsize=16, pad=20)
plt.xlabel("Activity Month (year_month)")
plt.ylabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.grid(False)

# âœ… Adjust layout BEFORE adding figtext
plt.tight_layout()

# âœ… Add footnote (after tight_layout)
plt.figtext(
    0.5, -0.05,
    "Note: Nov 2019 and Nov 2020 are partial months â€“ values may be underrepresented.",
    wrap=True,
    horizontalalignment='center',
    fontsize=10,
    color='gray'
)

# ğŸ’¾ Save the heatmap with indexed filename and bbox to include footnote
plot_filename = f"{PLOT_INDEX:02d}_cohort_retention_heatmap.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path, bbox_inches='tight')  # âœ… This includes the note!
    safe_print(f"âœ… Retention heatmap saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving (already exists): {plot_path}")

plt.show()

# ğŸ” Increment plot index
PLOT_INDEX += 1


# In[15]:


import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd

safe_print("ğŸ“Š Recalculating retention matrix and generating heatmap (excluding partial cohorts and months)...\n")

# ğŸ”» Remove partial cohort rows and observation columns
partial_months = ['2019-11', '2020-11']
filtered_usage = cohort_usage_matrix.drop(index=partial_months, columns=partial_months, errors='ignore')

# ğŸ” Normalize each cohort row by its first value
filtered_retention_matrix = filtered_usage.astype(float).copy()

for idx, row in filtered_retention_matrix.iterrows():
    first_value = row.loc[idx] if idx in row else None
    if pd.notna(first_value) and first_value > 0:
        filtered_retention_matrix.loc[idx] = (row / first_value).round(3)
    else:
        filtered_retention_matrix.loc[idx] = 0.0

# âœ… Preview
safe_print("ğŸ“‹ Filtered retention matrix (proportions):")
display(filtered_retention_matrix)

# ğŸ’¾ Save the filtered matrix
filtered_retention_path = os.path.join(
    project_base_path,
    'cohort_outputs', 'data', 'cohort_retention_matrix_filtered.csv'
)
os.makedirs(os.path.dirname(filtered_retention_path), exist_ok=True)
filtered_retention_matrix.to_csv(filtered_retention_path)
safe_print(f"ğŸ’¾ Filtered retention matrix saved to: {filtered_retention_path}")

# ğŸ¨ Plot heatmap
plt.figure(figsize=(14, 8))
sns.heatmap(
    filtered_retention_matrix,
    annot=True,
    fmt='.2f',
    cmap='YlGnBu',
    linewidths=0.5,
    cbar_kws={'label': 'Retention Rate'}
)

plt.title("Monthly Retention Rate per User Cohort (Excludes Nov 2019 & Nov 2020 â€“ Partial Months)")
plt.xlabel("Activity Month (year_month)")
plt.ylabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()

# ğŸ’¾ Save the plot with indexed filename
plot_filename = f"{PLOT_INDEX:02d}_cohort_retention_heatmap_filtered.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if 'OVERWRITE_PLOTS' not in globals():
    OVERWRITE_PLOTS = False

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… Filtered retention heatmap saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()

# ğŸ” Increment plot index
PLOT_INDEX += 1


# In[16]:


# ğŸ“ˆ Plot retention curves for selected strong cohorts only
import matplotlib.pyplot as plt

safe_print("ğŸ“ˆ Plotting retention curves for selected cohorts: 2020-02 to 2020-05...\n")

# ğŸ”„ Load the filtered retention matrix
filtered_retention_path = os.path.join(
    project_base_path,
    'cohort_outputs', 'data', 'cohort_retention_matrix_filtered.csv'
)
filtered_retention_matrix = pd.read_csv(filtered_retention_path, index_col=0)

# âœ… Define selected cohorts to plot
selected_cohorts = ['2020-02', '2020-03', '2020-04', '2020-05']

# ğŸ¨ Plot the curves
plt.figure(figsize=(12, 7))

for cohort_label in selected_cohorts:
    if cohort_label in filtered_retention_matrix.index:
        cohort_values = filtered_retention_matrix.loc[cohort_label]
        plt.plot(cohort_values.index, cohort_values.values, marker='o', label=cohort_label)

plt.title("Retention Curves â€“ Selected Cohorts (Filtered)", fontsize=16, pad=20)
plt.xlabel("Activity Month (year_month)")
plt.ylabel("Retention Rate")
plt.xticks(rotation=45)
plt.ylim(0, 1.05)
plt.grid(True)
plt.legend(title="Cohort", loc='upper right')
plt.tight_layout()

# ğŸ’¾ Save with next plot index
plot_filename = f"{PLOT_INDEX:02d}_cohort_retention_curves_selected.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… Selected cohort retention curves saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()

# ğŸ” Increment plot index
PLOT_INDEX += 1


# In[17]:


# âš ï¸ Step 14: Incident Rate per Cohort
safe_print("\nâš ï¸ Calculating incident rate per cohort...\n")

try:
    # ğŸ”¢ Count total and incident requests per cohort
    total_counts = (
        merged_cash_fee_cohort
        .groupby('cohort_year_month')
        .size()
        .rename('total_requests')
    )

    incident_counts = (
        merged_cash_fee_cohort[merged_cash_fee_cohort['incident_flag'] == 'incident']
        .groupby('cohort_year_month')
        .size()
        .rename('incident_requests')
    )

    # ğŸ§® Combine and calculate rate
    incident_df = pd.concat([total_counts, incident_counts], axis=1).fillna(0)
    incident_df['incident_rate'] = (incident_df['incident_requests'] / incident_df['total_requests']).round(4)

    # âœ… Display
    safe_print("ğŸ“‹ Incident Rate per Cohort:")
    display(incident_df)

    # ğŸ’¾ Save to CSV
    output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_incident_rate.csv')
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    incident_df.to_csv(output_path)
    safe_print(f"\nğŸ’¾ Incident rate data saved to: {output_path}")

except Exception as e:
    safe_print("âŒ Failed to calculate incident rate.")
    raise e


# In[18]:


import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.lines import Line2D
import os
import pandas as pd

safe_print("ğŸ“ˆ Plotting annotated incident rate bar chart per cohort...")

# ğŸ”„ Load incident rate data
incident_rate_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_incident_rate.csv')
incident_df = pd.read_csv(incident_rate_path, index_col=0)
incident_df.index = incident_df.index.astype(str)

# ğŸ“Š Plot config
plt.figure(figsize=(12, 6))
barplot = sns.barplot(
    x=incident_df.index,
    y=incident_df['incident_rate'],
    hue=incident_df.index,
    palette="OrRd",
    legend=False
)

# ğŸ§¾ Annotate each bar with its incident rate
for index, bar in enumerate(barplot.patches):
    height = bar.get_height()
    label = f"{height:.1%}"  # e.g., 25.2%
    barplot.annotate(
        label,
        (bar.get_x() + bar.get_width() / 2, height),
        ha='center',
        va='bottom',
        fontsize=9,
        color='black',
        xytext=(0, 3),
        textcoords='offset points'
    )

plt.title("Incident Rate per User Cohort", fontsize=16, pad=15)
plt.ylabel("Incident Rate")
plt.xlabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.ylim(0, incident_df['incident_rate'].max() + 0.05)
plt.grid(axis='y')

# ğŸ”» Mark partial months
partial_months = ['2019-11', '2020-11']
for partial_month in partial_months:
    if partial_month in incident_df.index:
        idx = list(incident_df.index).index(partial_month)
        plt.axvline(x=idx, color='red', linestyle='--', linewidth=1.5)

# ğŸ”» Mark start of 2020
start_2020 = '2020-01'
if start_2020 in incident_df.index:
    idx = list(incident_df.index).index(start_2020)
    plt.axvline(x=idx, color='black', linestyle='--', linewidth=1.5)

# ğŸ§¾ Custom legend
custom_lines = [
    Line2D([0], [0], color='red', linestyle='--', lw=2),
    Line2D([0], [0], color='black', linestyle='--', lw=2)
]
plt.legend(
    custom_lines,
    ['âš ï¸ Partial Month', '2020 Begins'],
    loc='upper right'
)

plt.tight_layout()

# ğŸ’¾ Save plot
plot_filename = f"{PLOT_INDEX:02d}_cohort_incident_rate.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… Incident rate chart saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()

# ğŸ” Increment plot index
PLOT_INDEX += 1


# In[19]:


import pandas as pd
import os

safe_print("ğŸ’° Calculating revenue per cohort...")

# ğŸ”„ Load merged dataset
merged_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'merged_cash_fee_cohort.csv')
merged_df = pd.read_csv(merged_path)

# ğŸ’° Filter for accepted fees only
accepted_fees = merged_df[merged_df['fee_status'] == 'accepted']

# ğŸ§® Group by cohort and sum total_amount
cohort_revenue = (
    accepted_fees.groupby('cohort_year_month')['total_amount']
    .sum()
    .reset_index(name='cohort_revenue')
    .sort_values(by='cohort_year_month')
)

# âœ… Display table
safe_print("ğŸ“‹ Cohort Revenue:")
display(cohort_revenue)

# ğŸ’¾ Save to file
revenue_output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_revenue.csv')
os.makedirs(os.path.dirname(revenue_output_path), exist_ok=True)
cohort_revenue.to_csv(revenue_output_path, index=False)
safe_print(f"ğŸ’¾ Revenue data saved to: {revenue_output_path}")

# ğŸ“ Partial month note
safe_print("\n*ï¸âƒ£ Note: '2019-11' and '2020-11' are partial months.\n- Nov 2019: Data starts on the 19th.\n- Nov 2020: Data ends on the 1st.\nRevenue from these cohorts is expected to be lower and should not be compared directly.")


# In[20]:


import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd
from matplotlib.lines import Line2D

safe_print("ğŸ“ˆ Plotting revenue per cohort...")

# ğŸ”„ Load revenue data
revenue_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_revenue.csv')
revenue_df = pd.read_csv(revenue_path)

# ğŸ“Š Plot setup
plt.figure(figsize=(12, 6))
barplot = sns.barplot(
    data=revenue_df,
    x='cohort_year_month',
    y='cohort_revenue',
    color='#4c72b0'
)

# ğŸ’¬ Annotate each bar with its value
for bar in barplot.patches:
    height = bar.get_height()
    label = f"â‚¬{int(height):,}"  # e.g., â‚¬11,135
    barplot.annotate(
        label,
        (bar.get_x() + bar.get_width() / 2, height),
        ha='center',
        va='bottom',
        fontsize=9,
        color='black',
        xytext=(0, 3),
        textcoords='offset points'
    )

# âš ï¸ Mark partial months
partial_months = ['2019-11', '2020-11']
for partial in partial_months:
    if partial in revenue_df['cohort_year_month'].values:
        idx = revenue_df[revenue_df['cohort_year_month'] == partial].index[0]
        plt.axvline(x=idx, color='red', linestyle='--', linewidth=1.5)

# ğŸ“Œ Mark beginning of 2020
if '2020-01' in revenue_df['cohort_year_month'].values:
    jan_idx = revenue_df[revenue_df['cohort_year_month'] == '2020-01'].index[0]
    plt.axvline(x=jan_idx, color='black', linestyle='--', linewidth=1.5)

# ğŸ–¼ï¸ Titles and labels
plt.title("Total Revenue per User Cohort", fontsize=16, pad=15)
plt.ylabel("Total Revenue (â‚¬)")
plt.xlabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.grid(axis='y')

# ğŸ§­ Custom legend
legend_lines = [
    Line2D([0], [0], color='#4c72b0', lw=4),
    Line2D([0], [0], color='red', linestyle='--', lw=2),
    Line2D([0], [0], color='black', linestyle='--', lw=2),
]
plt.legend(legend_lines, ['Revenue', 'âš ï¸ Partial Month', '2020 Begins'], loc='upper left')

# ğŸ’¾ Save plot
plot_filename = f"{PLOT_INDEX:02d}_cohort_revenue_bar.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… Revenue chart saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()

# ğŸ” Increment plot index
PLOT_INDEX += 1


# In[21]:


safe_print("ğŸ“ˆ Calculating cumulative revenue over time...")

# ğŸ”„ Load cohort revenue
revenue_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_revenue.csv')
revenue_df = pd.read_csv(revenue_path)

# ğŸ“Š Sort and compute cumulative sum
revenue_df = revenue_df.sort_values("cohort_year_month")
revenue_df["cumulative_revenue"] = revenue_df["cohort_revenue"].cumsum()

# ğŸ’¾ Save the cumulative revenue table
cumulative_table_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_cumulative_revenue.csv')
os.makedirs(os.path.dirname(cumulative_table_path), exist_ok=True)
revenue_df.to_csv(cumulative_table_path, index=False)
safe_print(f"ğŸ’¾ Cumulative revenue table saved to: {cumulative_table_path}")

# ğŸ–¥ï¸ Show table before plot
safe_print("ğŸ“‹ Cumulative Revenue by Month:")
display(revenue_df[["cohort_year_month", "cohort_revenue", "cumulative_revenue"]])

# â• Note about partial months
safe_print("\n*ï¸âƒ£ Note: `2019-11` and `2020-11` are partial months and should be interpreted cautiously.\n")

# ğŸ“ˆ Plot cumulative revenue line chart
plt.figure(figsize=(12, 6))
plt.plot(revenue_df["cohort_year_month"], revenue_df["cumulative_revenue"], marker='o', linewidth=3)
plt.title("Cumulative Revenue Over Time", fontsize=16, pad=15)
plt.xlabel("Cohort (cohort_year_month)")
plt.ylabel("Cumulative Revenue (â‚¬)")
plt.xticks(rotation=45)
plt.grid(True)

# ğŸ”» Add vertical dashed lines for partial months and Jan 2020
partial_months = ['2019-11', '2020-11']
for month in partial_months:
    if month in revenue_df["cohort_year_month"].values:
        idx = revenue_df[revenue_df["cohort_year_month"] == month].index[0]
        plt.axvline(x=idx, color='red', linestyle='--', linewidth=1.5)

# ğŸ¯ Mark where 2020 starts
if "2020-01" in revenue_df["cohort_year_month"].values:
    jan_idx = revenue_df[revenue_df["cohort_year_month"] == "2020-01"].index[0]
    plt.axvline(x=jan_idx, color='black', linestyle='--', linewidth=1.5)

# ğŸ“˜ Legend
custom_lines = [
    plt.Line2D([0], [0], color='blue', lw=3),
    plt.Line2D([0], [0], color='red', linestyle='--', lw=2),
    plt.Line2D([0], [0], color='black', linestyle='--', lw=2)
]
plt.legend(custom_lines, ['Cumulative Revenue', 'âš ï¸ Partial Month', '2020 Begins'])

# ğŸ’¾ Save plot
plot_filename = f"{PLOT_INDEX:02d}_cohort_revenue_cumulative_line.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… Cumulative revenue chart saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()
PLOT_INDEX += 1


# In[22]:


import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd

# ğŸ’¸ ARPU (Average Revenue Per User) per Cohort
safe_print("ğŸ’¸ Calculating ARPU (Average Revenue Per User) per cohort...")

# ğŸ“‚ Define paths
revenue_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_revenue.csv')
user_map_path = os.path.join(project_base_path, 'eda_outputs', 'data', 'user_first_request.csv')

# ğŸ“¥ Load revenue and user-cohort mapping
cohort_revenue = pd.read_csv(revenue_path)
user_first_request = pd.read_csv(user_map_path)

# ğŸ‘¥ Count users per cohort
cohort_user_counts = (
    user_first_request.groupby('cohort_year_month')
    .size()
    .reset_index(name='user_count')
)

# ğŸ”— Merge revenue and user counts
arpu_df = pd.merge(cohort_revenue, cohort_user_counts, on='cohort_year_month', how='left')

# ğŸ§® Calculate ARPU
arpu_df['arpu'] = (arpu_df['cohort_revenue'] / arpu_df['user_count']).round(2)

# ğŸ“‹ Preview table
safe_print("ğŸ“‹ ARPU per Cohort:")
display(arpu_df)

# â• Note about partial months
safe_print("\n*ï¸âƒ£ Note: `2019-11` and `2020-11` are partial months and should be interpreted cautiously.\n")

# ğŸ’¾ Save to CSV
arpu_output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_arpu.csv')
os.makedirs(os.path.dirname(arpu_output_path), exist_ok=True)
arpu_df.to_csv(arpu_output_path, index=False)
safe_print(f"ğŸ’¾ ARPU data saved to: {arpu_output_path}")

# ğŸ“Š Bar plot of ARPU
plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=arpu_df, x='cohort_year_month', y='arpu', color='#55a868')

# ğŸ’¬ Add ARPU value labels above bars
for bar in barplot.patches:
    height = bar.get_height()
    label = f"â‚¬{height:.2f}"
    barplot.annotate(
        label,
        (bar.get_x() + bar.get_width() / 2, height),
        ha='center',
        va='bottom',
        fontsize=9,
        color='black',
        xytext=(0, 3),
        textcoords='offset points'
    )

# ğŸ“Œ Titles and axes
plt.title("ARPU per User Cohort", fontsize=16, pad=15)
plt.ylabel("ARPU (â‚¬)")
plt.xlabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.grid(axis='y')

# ğŸ”» Mark partial months
partial_months = ['2019-11', '2020-11']
for partial in partial_months:
    if partial in arpu_df['cohort_year_month'].values:
        idx = arpu_df[arpu_df['cohort_year_month'] == partial].index[0]
        plt.axvline(x=idx, color='red', linestyle='--', linewidth=1.5)

# âš« Add 2020 start line
if '2020-01' in arpu_df['cohort_year_month'].values:
    idx = arpu_df[arpu_df['cohort_year_month'] == '2020-01'].index[0]
    plt.axvline(x=idx, color='black', linestyle='--', linewidth=1.5)

# ğŸ§¾ Custom legend
custom_lines = [
    plt.Line2D([0], [0], color='#55a868', lw=4),
    plt.Line2D([0], [0], color='red', linestyle='--', lw=2),
    plt.Line2D([0], [0], color='black', linestyle='--', lw=2)
]
plt.legend(custom_lines, ['ARPU', 'âš ï¸ Partial Month', '2020 Begins'], loc='upper right')

# ğŸ’¾ Save plot
plot_filename = f"{PLOT_INDEX:02d}_cohort_arpu_bar.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… ARPU chart saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()
PLOT_INDEX += 1


# In[23]:


import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.lines import Line2D
import os
import pandas as pd

# ğŸ“Œ Calculate Customer Lifetime Value (CLV)
safe_print("ğŸ’¡ Calculating CLV (Customer Lifetime Value)...")

# ğŸ“¥ Load ARPU and filtered retention matrix
arpu_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_arpu.csv')
retention_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_retention_matrix_filtered.csv')

arpu_df = pd.read_csv(arpu_path)
retention_df = pd.read_csv(retention_path, index_col=0)

# ğŸ”¢ Calculate average retention duration: count non-zero months per cohort
retention_binary = retention_df.gt(0).astype(int)
avg_retention_months = retention_binary.sum(axis=1).rename("avg_retention_months").reset_index()

# ğŸ”— Merge with ARPU
clv_df = arpu_df.merge(avg_retention_months, on='cohort_year_month', how='left')
clv_df['clv'] = (clv_df['arpu'] * clv_df['avg_retention_months']).round(2)

# ğŸ§¹ Exclude partial cohorts from both table and plot
partial_months = ['2019-11', '2020-11']
clv_df = clv_df[~clv_df['cohort_year_month'].isin(partial_months)]

# ğŸ’¾ Save CLV table
clv_output_path = os.path.join(project_base_path, 'cohort_outputs', 'data', 'cohort_clv.csv')
clv_df.to_csv(clv_output_path, index=False)
safe_print(f"ğŸ’¾ CLV data saved to: {clv_output_path}")

# ğŸ“‹ Preview table before plotting
safe_print("ğŸ“‹ CLV per Cohort:")
display(clv_df)

# ğŸ“Š Plot CLV per cohort
plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=clv_df, x='cohort_year_month', y='clv', color='#4c72b0')

# ğŸ’¬ Add CLV labels above bars
for bar in barplot.patches:
    height = bar.get_height()
    label = f"â‚¬{height:.2f}"
    barplot.annotate(
        label,
        (bar.get_x() + bar.get_width() / 2, height),
        ha='center',
        va='bottom',
        fontsize=9,
        color='black',
        xytext=(0, 3),
        textcoords='offset points'
    )

# ğŸ“Œ Titles and axes
plt.title("Customer Lifetime Value per User Cohort", fontsize=16, pad=15)
plt.ylabel("CLV (â‚¬)")
plt.xlabel("Cohort (cohort_year_month)")
plt.xticks(rotation=45)
plt.grid(axis='y')

# ğŸ”» Mark start of 2020 (centered on '2020-01')
if '2020-01' in clv_df['cohort_year_month'].values:
    x_labels = list(clv_df['cohort_year_month'])
    x_pos = x_labels.index('2020-01')
    plt.axvline(x=x_pos, color='black', linestyle='--', linewidth=1.5)

# ğŸ§¾ Custom legend
custom_lines = [
    Line2D([0], [0], color='#4c72b0', lw=4),
    Line2D([0], [0], color='black', linestyle='--', lw=2),
]
plt.legend(custom_lines, ['CLV', '2020 Begins'], loc='upper right')

# ğŸ’¾ Save plot
plot_filename = f"{PLOT_INDEX:02d}_cohort_clv_bar.png"
plot_path = os.path.join(project_base_path, 'cohort_outputs', 'plots', plot_filename)
os.makedirs(os.path.dirname(plot_path), exist_ok=True)

if OVERWRITE_PLOTS or not os.path.exists(plot_path):
    plt.savefig(plot_path)
    safe_print(f"âœ… CLV chart saved to: {plot_path}")
else:
    safe_print(f"âš ï¸ Skipped saving â€“ file already exists: {plot_path}")

plt.show()
PLOT_INDEX += 1


# In[24]:


if __name__ == "__main__":
    safe_print("ğŸš€ Script executed directly as a .py file â€” all code above has already run in notebook order.")



# ------------------------------------------------------------------------------
# ğŸ›¡ï¸ License & Attribution
#
# Â© 2024 Ginosca Alejandro DÃ¡vila
# Project: Ironhack Payments â€“ Cohort Analysis
# Bootcamp: Ironhack Data Science and Machine Learning
#
# This work is provided for educational purposes under the MIT License.
# You may reuse, modify, or redistribute with attribution.
# ------------------------------------------------------------------------------
